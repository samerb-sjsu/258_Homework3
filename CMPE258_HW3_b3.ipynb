{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CMPE258_HW3_b3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDr7ACJNAo_I"
      },
      "source": [
        "# HW3: Part b3. PyTorch Neural Network with Auto Differentiation - High Level\n",
        "\n",
        "##CMPE-258: Deep Learning, Vijay Eranti\n",
        "##Samer Baslan\n",
        "##SJSU Spring 2021\n",
        "\n",
        "#Reference: https://www.gcptutorials.com/post/how-to-build-basic-neural-network-with-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyjqttRd-tvf"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbQofHF3B9GH"
      },
      "source": [
        "##Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ichubpPnA3CB"
      },
      "source": [
        "batch_size, input_dim, hidden_dim, out_dim = 32, 3, 10, 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA4ZULRaAu42"
      },
      "source": [
        "input_tensor = torch.randn(batch_size, input_dim)\n",
        "output_tensor = torch.randn(batch_size, out_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxKMH1_xB_Cf"
      },
      "source": [
        "##Define Model using nn package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xAoNRRUBSnl"
      },
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(input_dim, hidden_dim),\n",
        "    torch.nn.Linear(hidden_dim, hidden_dim),\n",
        "    torch.nn.Tanh(),\n",
        "    torch.nn.Linear(hidden_dim, out_dim),\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSE1BKOxCB82"
      },
      "source": [
        "##Define loss function, optimizer, and learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y35ncC5rBg2p"
      },
      "source": [
        "loss_function = torch.nn.MSELoss(reduction = 'sum')\n",
        "\n",
        "lr = 1e-5\n",
        "\n",
        "sgd_optimizer = torch.optim.SGD(model.parameters(), lr = lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZyZZbP8CF6x"
      },
      "source": [
        "##Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psjilvHJBsFO",
        "outputId": "2a614ec7-7b0a-4366-f2c9-4bd19a4320ef"
      },
      "source": [
        "for i in range(200):\n",
        "  predicted_value = model(input_tensor)\n",
        "  loss = loss_function(predicted_value, output_tensor)\n",
        "  print(i, loss.item())\n",
        "\n",
        "  sgd_optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  sgd_optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 62.1256103515625\n",
            "1 62.11815643310547\n",
            "2 62.11072540283203\n",
            "3 62.103302001953125\n",
            "4 62.09590148925781\n",
            "5 62.08850860595703\n",
            "6 62.08114242553711\n",
            "7 62.07377243041992\n",
            "8 62.066436767578125\n",
            "9 62.059104919433594\n",
            "10 62.051795959472656\n",
            "11 62.044498443603516\n",
            "12 62.037208557128906\n",
            "13 62.029937744140625\n",
            "14 62.02268981933594\n",
            "15 62.01545333862305\n",
            "16 62.00822448730469\n",
            "17 62.00101852416992\n",
            "18 61.99382019042969\n",
            "19 61.98664855957031\n",
            "20 61.9794807434082\n",
            "21 61.97233200073242\n",
            "22 61.96519470214844\n",
            "23 61.95807647705078\n",
            "24 61.950965881347656\n",
            "25 61.94387435913086\n",
            "26 61.93679428100586\n",
            "27 61.92973327636719\n",
            "28 61.92268371582031\n",
            "29 61.9156494140625\n",
            "30 61.90863037109375\n",
            "31 61.90162658691406\n",
            "32 61.89463424682617\n",
            "33 61.88764953613281\n",
            "34 61.88068771362305\n",
            "35 61.87374496459961\n",
            "36 61.86680603027344\n",
            "37 61.859886169433594\n",
            "38 61.85297393798828\n",
            "39 61.84608459472656\n",
            "40 61.83920669555664\n",
            "41 61.83234405517578\n",
            "42 61.82548522949219\n",
            "43 61.81865692138672\n",
            "44 61.811832427978516\n",
            "45 61.80501937866211\n",
            "46 61.79822540283203\n",
            "47 61.791446685791016\n",
            "48 61.78467559814453\n",
            "49 61.777923583984375\n",
            "50 61.771175384521484\n",
            "51 61.76445388793945\n",
            "52 61.75774002075195\n",
            "53 61.75103759765625\n",
            "54 61.744354248046875\n",
            "55 61.73767852783203\n",
            "56 61.73101806640625\n",
            "57 61.724369049072266\n",
            "58 61.71773910522461\n",
            "59 61.71112060546875\n",
            "60 61.70451354980469\n",
            "61 61.69792175292969\n",
            "62 61.69133758544922\n",
            "63 61.68476867675781\n",
            "64 61.678218841552734\n",
            "65 61.67167663574219\n",
            "66 61.66515350341797\n",
            "67 61.658634185791016\n",
            "68 61.65213394165039\n",
            "69 61.64564895629883\n",
            "70 61.6391716003418\n",
            "71 61.63270568847656\n",
            "72 61.62626266479492\n",
            "73 61.61981964111328\n",
            "74 61.613399505615234\n",
            "75 61.60698699951172\n",
            "76 61.600589752197266\n",
            "77 61.594207763671875\n",
            "78 61.58783721923828\n",
            "79 61.58147430419922\n",
            "80 61.57512664794922\n",
            "81 61.56879425048828\n",
            "82 61.56246566772461\n",
            "83 61.5561637878418\n",
            "84 61.549861907958984\n",
            "85 61.5435791015625\n",
            "86 61.53730773925781\n",
            "87 61.53104782104492\n",
            "88 61.52479553222656\n",
            "89 61.51856994628906\n",
            "90 61.51234436035156\n",
            "91 61.506134033203125\n",
            "92 61.49993133544922\n",
            "93 61.493751525878906\n",
            "94 61.487579345703125\n",
            "95 61.48141860961914\n",
            "96 61.47526931762695\n",
            "97 61.46913528442383\n",
            "98 61.463008880615234\n",
            "99 61.45689392089844\n",
            "100 61.450801849365234\n",
            "101 61.44470977783203\n",
            "102 61.438636779785156\n",
            "103 61.43256378173828\n",
            "104 61.426517486572266\n",
            "105 61.42048263549805\n",
            "106 61.41444778442383\n",
            "107 61.4084358215332\n",
            "108 61.40242385864258\n",
            "109 61.39643096923828\n",
            "110 61.39045715332031\n",
            "111 61.38448715209961\n",
            "112 61.37853240966797\n",
            "113 61.372581481933594\n",
            "114 61.36664581298828\n",
            "115 61.3607177734375\n",
            "116 61.354820251464844\n",
            "117 61.34892272949219\n",
            "118 61.343017578125\n",
            "119 61.33715057373047\n",
            "120 61.33128356933594\n",
            "121 61.32543182373047\n",
            "122 61.3195915222168\n",
            "123 61.31376647949219\n",
            "124 61.307945251464844\n",
            "125 61.30213165283203\n",
            "126 61.29634475708008\n",
            "127 61.290557861328125\n",
            "128 61.2847785949707\n",
            "129 61.279022216796875\n",
            "130 61.27326583862305\n",
            "131 61.26752471923828\n",
            "132 61.261802673339844\n",
            "133 61.25607681274414\n",
            "134 61.2503776550293\n",
            "135 61.24468231201172\n",
            "136 61.23899459838867\n",
            "137 61.23332214355469\n",
            "138 61.2276611328125\n",
            "139 61.222007751464844\n",
            "140 61.21636962890625\n",
            "141 61.21073913574219\n",
            "142 61.205116271972656\n",
            "143 61.19951629638672\n",
            "144 61.19392395019531\n",
            "145 61.188331604003906\n",
            "146 61.182762145996094\n",
            "147 61.17719650268555\n",
            "148 61.17163848876953\n",
            "149 61.16609191894531\n",
            "150 61.16056823730469\n",
            "151 61.1550407409668\n",
            "152 61.14952850341797\n",
            "153 61.14402770996094\n",
            "154 61.13854217529297\n",
            "155 61.1330680847168\n",
            "156 61.12759017944336\n",
            "157 61.12214279174805\n",
            "158 61.1166877746582\n",
            "159 61.11125564575195\n",
            "160 61.10582733154297\n",
            "161 61.10041046142578\n",
            "162 61.095008850097656\n",
            "163 61.0896110534668\n",
            "164 61.084228515625\n",
            "165 61.07884979248047\n",
            "166 61.073490142822266\n",
            "167 61.06813430786133\n",
            "168 61.06279373168945\n",
            "169 61.057456970214844\n",
            "170 61.05213165283203\n",
            "171 61.04682159423828\n",
            "172 61.04151916503906\n",
            "173 61.03622817993164\n",
            "174 61.03094482421875\n",
            "175 61.025672912597656\n",
            "176 61.020408630371094\n",
            "177 61.015159606933594\n",
            "178 61.009910583496094\n",
            "179 61.00468444824219\n",
            "180 60.99946212768555\n",
            "181 60.99424743652344\n",
            "182 60.989051818847656\n",
            "183 60.983856201171875\n",
            "184 60.978675842285156\n",
            "185 60.9734992980957\n",
            "186 60.96833801269531\n",
            "187 60.96318435668945\n",
            "188 60.95804977416992\n",
            "189 60.95290756225586\n",
            "190 60.947784423828125\n",
            "191 60.94267272949219\n",
            "192 60.937564849853516\n",
            "193 60.93246841430664\n",
            "194 60.92738342285156\n",
            "195 60.92230987548828\n",
            "196 60.9172477722168\n",
            "197 60.91218948364258\n",
            "198 60.90714645385742\n",
            "199 60.902103424072266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbrTE_yfB22U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}